{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Subnational to SVI\n",
    "Compare subnational data to SVI data in the USA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt # display\n",
    "import seaborn as sns # display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set wd\n",
    "wd_path = \"C:\\\\Users\\\\rcompos\\\\OneDrive - North Carolina State University\\\\Documents\\\\Research\\\\SVI_Flood_Project\"\n",
    "os.chdir(wd_path)\n",
    "os.getcwd() # get wd\n",
    "#os.listdir() # get available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "sub = pd.read_csv(\"Subnational\\\\sub_pov - selections.csv\")\n",
    "svi_cnty = pd.read_csv(\"SVI\\\\SVI2020_US_COUNTY.csv\")\n",
    "svi_tra = pd.read_csv(\"SVI\\\\SVI2020_US_tract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data\n",
    "\n",
    "#sub.head(5)\n",
    "#svi_cnty.head(5)\n",
    "#svi_tra.head(5)\n",
    "#sub.dtypes\n",
    "#svi_cnty.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep subnational data to add to svi\n",
    "sub_usa = sub[sub['code'] == 'USA'] # select usa data\n",
    "#len(sub_usa) # 51, includes D.C.\n",
    "#print(sub_usa[['STATE']].to_string(index=False)) # get list of states\n",
    "\n",
    "sub_usa = sub_usa.rename(columns = {'State':'STATE','Mean Rank (SVI)':'sub_mean_rank'}) # rename column to match svi data\n",
    "sub_usa = sub_usa[['STATE','sub_mean_rank']] # select columns\n",
    "sub_usa['sub_mean_rank'] = sub_usa['sub_mean_rank'].astype(float)\n",
    "#print(sub_usa.dtypes)\n",
    "\n",
    "#sub_usa.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to group & filter svi data\n",
    "\n",
    "# Group svi data by state\n",
    "#svi_st_m = svi_cnty.groupby('STATE').mean().reset_index()\n",
    "# svi_st_m_s = svi_st_m.iloc[:,np.r_[0, 11:40]] # filter columns\n",
    "#len(svi_st_m) # 51, includes D.C.\n",
    "#svi_st_m_s.head(5)\n",
    "#print(svi_st_m[['STATE']].to_string(index=False)) # get list of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine svi & subnational datasets\n",
    "\n",
    "# Combine by state median\n",
    "svi_st_med = svi_cnty.groupby('STATE').median().reset_index()\n",
    "svi_st_med_merged = pd.merge(sub_usa, svi_st_med, on =['STATE'], how = 'left')\n",
    "#svi_st_med_merged.head()\n",
    "\n",
    "# Combine by state mean\n",
    "svi_st_m = svi_cnty.groupby('STATE').mean().reset_index()\n",
    "svi_st_merged = pd.merge(sub_usa, svi_st_m, on =['STATE'], how = 'left')\n",
    "#svi_st_merged.head()\n",
    "#svi_merged.dtypes\n",
    "\n",
    "# Combine by county\n",
    "svi_cnty_merged = pd.merge(svi_cnty, sub_usa, on =['STATE'], how = 'left')\n",
    "#svi_cnty_merged.head()\n",
    "\n",
    "# Combine by tract\n",
    "svi_tra_merged = pd.merge(svi_tra, sub_usa, on =['STATE'], how = 'left')\n",
    "#svi_tra_merged.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare w/ simple linear correlation\n",
    "\n",
    "\n",
    "*Notes:* Closer to 0 is less correlated & closer to 1 or -1 is more correlated, datasets must be same length\n",
    "\n",
    "*Source:*  https://www.geeksforgeeks.org/exploring-correlation-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pearson correlations matrix\n",
    "\n",
    "# By state median\n",
    "svi_st_med_corr = svi_st_med_merged.corr(method = 'pearson') # run correlation\n",
    "print('Rank by State svi median')\n",
    "print(svi_st_med_corr[['sub_mean_rank']].sort_values(by='sub_mean_rank', ascending=False).head(7)) # order results\n",
    "print()\n",
    "\n",
    "# By state mean\n",
    "svi_st_corr = svi_st_merged.corr(method = 'pearson') # run correlation\n",
    "print('Rank by State svi mean')\n",
    "print(svi_st_corr[['sub_mean_rank']].sort_values(by='sub_mean_rank', ascending=False).head(7)) # order results\n",
    "print()\n",
    "\n",
    "# By county\n",
    "svi_cnty_corr = svi_cnty_merged.corr(method = 'pearson') # run correlation\n",
    "print('Rank by County')\n",
    "print(svi_cnty_corr[['sub_mean_rank']].sort_values(by='sub_mean_rank', ascending=False).head(3)) # order results\n",
    "print()\n",
    "\n",
    "# By tract\n",
    "svi_tra_corr = svi_tra_merged.corr(method = 'pearson') # run correlation\n",
    "#print('Rank by Tract')\n",
    "#print(svi_tra_corr[['sub_mean_rank']].sort_values(by='sub_mean_rank', ascending=False).head(5)) # order results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just themes\n",
    "svi_st_corr_trim = svi_st_corr[['RPL_THEMES','RPL_THEME1','RPL_THEME2','RPL_THEME3','RPL_THEME4','sub_mean_rank']]\n",
    "svi_st_corr_trim.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots of subnational & svi themes\n",
    "big_themes = ['RPL_THEMES','RPL_THEME1','RPL_THEME2','RPL_THEME3','RPL_THEME4','sub_mean_rank']\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(\"Subnational Mean Rank Correlation to SVI Themes\", fontsize=18, y=0.95)\n",
    "\n",
    "# Loop through indices of correlation\n",
    "for svi_col, ax in zip(big_themes, axs.ravel()):   \n",
    "        y=svi_st_merged['sub_mean_rank']\n",
    "        x=svi_st_merged[svi_col]\n",
    "\n",
    "        correlation = y.corr(x)\n",
    "\n",
    "        plt.plot(ax=ax)\n",
    "\n",
    "        # plot the data\n",
    "        ax.scatter(x, y)\n",
    " \n",
    "        # fits the best fitting line to the data\n",
    "        ax.plot(np.unique(x),\n",
    "            np.poly1d(np.polyfit(x, y, 1))\n",
    "            (np.unique(x)), color='red')\n",
    "        \n",
    "        ax.set_title(svi_col +\" w/ corr \" + str(round(correlation,4)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of SVI columns w/ higher correlation to subnational data\n",
    "\n",
    "# select all attributes in svi that have correlation w/ sub_mean_rank of >0.5 and <-.2\n",
    "svi_st_corr_sel = svi_st_corr[(svi_st_corr['sub_mean_rank'] < -.2) | (svi_st_corr['sub_mean_rank'] > .5)]\n",
    "#print(len(svi_st_corr_sel))\n",
    "#print(svi_st_corr_sel[['sub_mean_rank']].head(15))\n",
    "\n",
    "# create a list of these variables w/ these correlations\n",
    "svi_st_corr_sel = svi_st_corr_sel.sort_values(by='sub_mean_rank', ascending=False)\n",
    "iteratethis = svi_st_corr_sel.index.values.tolist()\n",
    "#print(iteratethis)\n",
    "print(len(iteratethis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots of subnational & svi correlation\n",
    "fig, axs = plt.subplots(nrows=6, ncols=3, figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(\"Subnational Mean Rank Correlation to SVI Columns\", fontsize=18, y=0.95)\n",
    "\n",
    "# Loop through indices of correlation\n",
    "for svi_col, ax in zip(iteratethis, axs.ravel()):   \n",
    "        y=svi_st_merged['sub_mean_rank']\n",
    "        x=svi_st_merged[svi_col]\n",
    "\n",
    "        correlation = y.corr(x)\n",
    "\n",
    "        plt.plot(ax=ax)\n",
    "\n",
    "        # plot the data\n",
    "        ax.scatter(x, y)\n",
    " \n",
    "        # fits the best fitting line to the data\n",
    "        ax.plot(np.unique(x),\n",
    "            np.poly1d(np.polyfit(x, y, 1))\n",
    "            (np.unique(x)), color='red')\n",
    "        \n",
    "        ax.set_title(svi_col +\" w/ corr \" + str(round(correlation,4)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots of correlation\n",
    "# Loop through certain indeces of correlation\n",
    "# plotting the data\n",
    "for svi_col in iteratethis:   \n",
    "        y=svi_st_merged['sub_mean_rank']\n",
    "        x=svi_st_merged[svi_col]\n",
    "\n",
    "        correlation = y.corr(x)\n",
    "\n",
    "        # adds the title\n",
    "        plt.title(svi_col +\" has correlation of \" + str(round(correlation,4)))\n",
    " \n",
    "        # plot the data\n",
    "        plt.scatter(x, y)\n",
    " \n",
    "        # fits the best fitting line to the data\n",
    "        plt.plot(np.unique(x),\n",
    "            np.poly1d(np.polyfit(x, y, 1))\n",
    "            (np.unique(x)), color='red')\n",
    " \n",
    "        # Labelling axes\n",
    "        plt.xlabel(i)\n",
    "        plt.ylabel('subnational mean rank')\n",
    "        \n",
    "        #plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions from \"SVI2020Documentation\"\n",
    "\n",
    "EPL_NOHSDP: Percentile percentage of persons with no high school diploma (age 25+) estimate\n",
    "EP_NOHSDP: Percentage of persons with no high school diploma (age 25+) estimate\n",
    "RPL_THEMES: Overall percentile ranking\n",
    "SPL_THEMES: Sum of series themes\n",
    "RPL_THEME1: Percentile ranking for Socioeconomic Status theme summary\n",
    "SPL_THEME1: Sum of series for Socioeconomic Status theme\n",
    "\n",
    "Four Themes: Socioeconomic status, househould characteristics, racial & ethnic minority status, housing type/transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other display options\n",
    "plt.figure(figsize=(10,8), dpi =500)\n",
    "sns.heatmap(svi_st_corr.head(10),annot=True,fmt=\".2f\", linewidth=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Add in HRLS Data (incomplete!!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: https://shakasom.medium.com/how-to-convert-latitude-longtitude-columns-in-csv-to-geometry-column-using-python-4219d2106dea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from shapely.geometry import Point # Shapely for converting latitude/longtitude to geometry\n",
    "import geopandas as gpd # To create GeodataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "hrls_kid = pd.read_csv(\"HRLS\\\\USA_children_under_five_2020-03-07.csv\")\n",
    "hrls_kid.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a geometry column \n",
    "geometry = [Point(xy) for xy in zip(hrls_kid['longitude'], hrls_kid['latitude'])]\n",
    "\n",
    "# Coordinate reference system : WGS84\n",
    "crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# Creating a Geographic data frame \n",
    "gdf = gpd.GeoDataFrame(hrls_kid, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all points\n",
    "gdf.plot(marker='o', color='b', markersize=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload states file\n",
    "states_path = \"States_Shape\\\\cb_2018_us_state_20m.shp\"\n",
    "states_shape = gpd.read_file(states_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join HRLS points to the states shapefile\n",
    "hrls_joined = gpd.sjoin(gdf, world, how=\"inner\", op='within')\n",
    "hrls_joined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate points to state level\n",
    "hrls_states = hrls_joined.groupby('NAME').agg('sum') # other options STUSPS (MD,IA,etc.), GEOID (24,19)\n",
    "hrls_states.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Combine HRLS & Subnational Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine HRLS and subnational data\n",
    "# new = d.merge(sub_usa, hrls, on =['STATE'], how = 'left')\n",
    "\n",
    "# take average of the 3 averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
